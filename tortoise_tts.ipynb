{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pIZ3ZXNp7cf"
   },
   "source": [
    "# Tortoise TTS (Original Repository)\n",
    "\n",
    "This notebook is designed for [@fakerybakery's guide](https://github.com/fakerybakery/tortoise-tts-guide) on running and fine-tuning Tortoise TTS.\n",
    "\n",
    "Before you begin, I **strongly** recommend you turn on a GPU runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JrK20I32grP6",
    "outputId": "9711e23e-3bfc-4cb0-c030-25a1cf460972"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/neonbjb/tortoise-tts\n",
    "%cd tortoise-tts\n",
    "!pip3 install -r requirements.txt\n",
    "!pip3 install -e .\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "!pip3 install deepspeed==0.9.0\n",
    "!pip install transformers==4.29.2 # to fix bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Gen09NM4hONQ"
   },
   "outputs": [],
   "source": [
    "#@title # Setup\n",
    "# Imports used through the rest of the notebook.\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import IPython\n",
    "\n",
    "from tortoise.api import TextToSpeech\n",
    "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
    "\n",
    "# This will download all the models used by Tortoise from the HuggingFace hub.\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bt_aoxONjfL2"
   },
   "outputs": [],
   "source": [
    "#@markdown This is the text that will be spoken. If you want longform audio, ignore the `text` element - we'll manually set it later. But still run this cell for the preset!\n",
    "\n",
    "text = \"Joining two modalities results in a surprising increase in generalization! What would happen if we combined them all?\" #@param {type:\"string\"}\n",
    "#@markdown Show code for multiline text input\n",
    "# Here's something for the poetically inclined.. (set text=)\n",
    "\"\"\"\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\"\"\"\n",
    "\n",
    "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\" (default), \"fast\", \"standard\", \"high_quality\"}. See docs in api.py\n",
    "preset = \"ultra_fast\" #@param [\"ultra_fast\", \"fast\", \"standard\", \"high_quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "SSleVnRAiEE2",
    "outputId": "45b950c7-5c39-4075-bb34-0a76bf19e1bc"
   },
   "outputs": [],
   "source": [
    "#@markdown Tortoise will attempt to mimic voices you provide. It comes pre-packaged\n",
    "#@markdown with some voices you might recognize.\n",
    "\n",
    "#@markdown Let's list all the voices available. These are just some random clips I've gathered\n",
    "#@markdown from the internet as well as a few voices from the training dataset.\n",
    "#@markdown Feel free to add your own clips to the voices/ folder.\n",
    "#%cd tortoise-tts-fast\n",
    "%ls tortoise/voices\n",
    "import IPython\n",
    "IPython.display.Audio(filename='tortoise/voices/tom/1.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Audio\n",
    "\n",
    "For short audio, skip to the short section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Long text here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = text.replace(\"\\n\", \" \").strip()\n",
    "sentences = nltk.sent_tokenize(script)\n",
    "\n",
    "voice = 'train_dotrice' # select voice\n",
    "\n",
    "audio_list = []\n",
    "voice_samples, conditioning_latents = load_voice(voice)\n",
    "for txt in sentences:\n",
    "\n",
    "    #@markdown Load it and send it through Tortoise.\n",
    "    gen = tts.tts_with_preset(txt, voice_samples=voice_samples, conditioning_latents=conditioning_latents, preset=preset, k=1)\n",
    "    audio_list.append(gen.squeeze(0).cpu())\n",
    "concatenated_audio = torch.cat(audio_list, dim=1)\n",
    "torchaudio.save('generated.wav', concatenated_audio, 24000)\n",
    "IPython.display.Audio('generated.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "KEXOKjIvn6NW",
    "outputId": "90c803f3-0b9b-4f24-ccbc-d3f3dcbde48c"
   },
   "outputs": [],
   "source": [
    "#@markdown Pick one of the voices from the output above\n",
    "voice = 'train_dotrice' #@param {type:\"string\"}\n",
    "text = 'Text' #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Load it and send it through Tortoise.\n",
    "voice_samples, conditioning_latents = load_voice(voice)\n",
    "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, \n",
    "                          preset=preset)\n",
    "torchaudio.save('generated.wav', gen.squeeze(0).cpu(), 24000)\n",
    "IPython.display.Audio('generated.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "16Xs2SSC3BXa",
    "outputId": "6d13d257-b6f1-4a73-9c42-c1c4ce560622"
   },
   "outputs": [],
   "source": [
    "#@markdown Tortoise can also generate speech using a random voice. The voice changes each time you execute this!\n",
    "#@markdown (Note: random voices can be prone to strange utterances)\n",
    "gen = tts.tts_with_preset(text, voice_samples=None, conditioning_latents=None, preset=preset)\n",
    "torchaudio.save('generated.wav', gen.squeeze(0).cpu(), 24000)\n",
    "IPython.display.Audio('generated.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 41
    },
    "id": "VQgw3KeV8Yqb",
    "outputId": "13db770e-3fcc-4b27-ab78-07a603a299d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-6766c9cf-33b5-49f0-8472-6468207c97c6\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-6766c9cf-33b5-49f0-8472-6468207c97c6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@markdown Optionally, upload use your own voice by running the next two cells. I recommend\n",
    "#@markdown you upload at least 2 audio clips. They must be a WAV file, 6-10 seconds long.\n",
    "CUSTOM_VOICE_NAME = \"custom\"\n",
    "\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "custom_voice_folder = f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"\n",
    "os.makedirs(custom_voice_folder)\n",
    "for i, file_data in enumerate(files.upload().values()):\n",
    "  with open(os.path.join(custom_voice_folder, f'{i}.wav'), 'wb') as f:\n",
    "    f.write(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJnJwv3R9uWT"
   },
   "outputs": [],
   "source": [
    "# Generate speech with the custotm voice.\n",
    "voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
    "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, \n",
    "                          preset=preset)\n",
    "torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 24000)\n",
    "IPython.display.Audio(f'generated-{CUSTOM_VOICE_NAME}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "fYTk8KUezUr5",
    "outputId": "3acc34ee-75fa-4f33-f1ce-ffcb4ed44eba"
   },
   "outputs": [],
   "source": [
    "# You can also combine conditioning voices. Combining voices produces a new voice\n",
    "# with traits from all the parents.\n",
    "#\n",
    "# Lets see what it would sound like if Picard and Kirk had a kid with a penchant for philosophy:\n",
    "voice_samples, conditioning_latents = load_voices(['pat', 'william'])\n",
    "\n",
    "gen = tts.tts_with_preset(\"They used to say that if man was meant to fly, heâ€™d have wings. But he did fly. He discovered he had to.\", \n",
    "                          voice_samples=voice_samples, conditioning_latents=conditioning_latents, \n",
    "                          preset=preset)\n",
    "torchaudio.save('captain_kirkard.wav', gen.squeeze(0).cpu(), 24000)\n",
    "IPython.display.Audio('captain_kirkard.wav')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
